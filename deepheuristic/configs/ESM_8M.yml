data:
  batch_size: 512
  num_workers: [0, 2] # local, hpc
training:
  num_epochs: 5
  lr: 0.0005
  min_lr: 0.00005
  weight_decay:  0.
  loss: "MSE"
  optimizer: "Adam"
model:
  model_dir: ["saved_models/ESM", null] # TODO: Change the path for HPC
  weights_path: ["weights/ESM_8M.pt", null] # TODO: Change the path for HPC
  name: "ESM_8M"
  num_layers: 6
  embed_dim: 320
  attention_heads: 20
  head_dropout: 0
  proj_dim: 8
